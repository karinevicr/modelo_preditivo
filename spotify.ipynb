{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "df = pd.read_csv('train.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificação e exploração inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() \n",
    "#Vejo algumas informações em relação as colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando se existe algum valor nulo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "#Aqui verifico se existe algum valor nulo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mais explorações de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)\n",
    "#Vejo 10 linhas aleatórias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "#Aqui vejo algumas estatísticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análise da Distribuição da Energia das Músicas\n",
    "\n",
    "Realizei uma exploração adicional dos dados, criando um histograma para visualizar a distribuição da energia das músicas. O gráfico mostra a frequência de músicas em diferentes níveis de energia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['energy'], bins=30, color='blue', alpha=0.7)\n",
    "plt.title('Distribuição da Energia das Músicas')\n",
    "plt.xlabel('Energy')\n",
    "plt.ylabel('Frequência')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulação de hipoteses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1° Hipotese: será que existe uma corrrelação entre a energia da musica com a popularidade? \n",
    "\n",
    "A primeira hipótese levantada foi se existe uma correlação entre o nível de energia das músicas e sua popularidade. A expectativa inicial era de que músicas mais enérgicas, por serem mais animadas e frequentemente tocadas em festas ou eventos, seriam mais populares.\n",
    "\n",
    "No entanto, a análise dos dados demonstrou que as músicas com menor nível de energia tendem a ser mais populares. Isso sugere que, embora as músicas energéticas sejam masi ouvidas em certos contextos, as músicas mais calmas ou menos agitadas podem ter maior gosto geral do público, possivelmente por serem mais usada para momentos de relaxamento ou consumo diário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_by_energy = df.groupby('energy')['popularity_target'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(popularity_by_energy['energy'], popularity_by_energy['popularity_target'], color='royalblue')\n",
    "\n",
    "plt.title('Popularity by Energy', fontsize=16)\n",
    "plt.xlabel('Energy', fontsize=14)\n",
    "plt.ylabel('Average Popularity', fontsize=14)\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "\n",
    "plt.xlim(0, 1)\n",
    "plt.xticks([round(i * 0.1, 1) for i in range(11)], fontsize=12)\n",
    "\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2° Hipotese: Corrrelação entre o genero musical com a popularidade?\n",
    "\n",
    "A hipótese analisada questiona se existe uma correlação entre o gênero musical e sua popularidade. Inicialmente, a expectativa era que gêneros como o funk, bastante popular no Brasil, estariam no topo da lista. No entanto, os dados não confirmaram essa hipótese.\n",
    "\n",
    "Para melhor visualização e análise, foram selecionados os 20 gêneros mais populares com base nos dados disponíveis. O gráfico abaixo demonstra que a relação entre gênero e popularidade é mais complexa do que o esperado, sugerindo que outros fatores além da nacionalidade ou o sucesso em um país específico podem influenciar na popularidade global das músicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_by_genre = df.groupby('track_genre')['popularity_target'].mean().reset_index()\n",
    "\n",
    "top_genres = popularity_by_genre.nlargest(20, 'popularity_target')\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(top_genres['track_genre'], top_genres['popularity_target'], color='lightblue')\n",
    "\n",
    "plt.title('Average Popularity by Track Genre', fontsize=16)\n",
    "plt.xlabel('Average Popularity', fontsize=14)\n",
    "plt.ylabel('Track Genre', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3° Hipotese: Correlação entre conteudo explicito e popularidade\n",
    "\n",
    "\n",
    "A terceira hipótese avaliada foi se músicas com conteúdo explícito possuem maior popularidade em relação às músicas sem esse tipo de conteúdo. A análise inicial indicou uma diferença em favor das músicas explícitas, que apresentam uma leve vantagem em termos de popularidade. No entanto, a diferença não é tão significativa quanto o esperado. Essa observação sugere que, embora o conteúdo explícito possa ser popular, ele não é um fator decisivo para a popularidade. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_by_explicit = df.groupby('explicit')['popularity_target'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(popularity_by_explicit['explicit'], popularity_by_explicit['popularity_target'], color='lightcoral')\n",
    "\n",
    "plt.title('Average Popularity by Explicit Content', fontsize=16)\n",
    "plt.xlabel('Explicit Content (0 = No, 1 = Yes)', fontsize=14)\n",
    "plt.ylabel('Average Popularity', fontsize=14)\n",
    "plt.xticks([0, 1], ['No', 'Yes'], fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificação de colunas categoricas e numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "print('Colunas numéricas:\\n', numeric_df.columns)\n",
    "#Verifica novamente quais são as colunas numéricas e categoricas\n",
    "#Esse trecho de codigo foi recolocado para verificar se alguma coluna é categorica\n",
    "categorical_df = df.select_dtypes(exclude=['number'])\n",
    "print('\\nColunas categóricas:\\n', categorical_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento nas Colunas Categóricas\n",
    "\n",
    "O **One-Hot Encoding** foi aplicado à coluna `track_genre`, transformando cada valor distinto dessa coluna em uma nova coluna binária. Esse método foi escolhido porque a variável `track_genre` não possui uma relação de ordem natural entre suas categorias, tornando o One-Hot Encoding uma escolha adequada para representar os diferentes gêneros musicais sem introduzir qualquer hierarquia entre eles.\n",
    "\n",
    "Além disso, as colunas `track_id`, `album_name`, `artists` e `track_name` foram removidas, pois essas variáveis são  identificadores únicos ou strings que não tem relação direta com a popularidade da música. Manter essas colunas poderia aumentar a dimensionalidade do modelo sem agregar valor ao modleo preditivo. Tirar elas ajuda a focar nas variáveis que tem impacto real na previsão de popularidade, como características numéricas e categorias relevantes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['track_genre'], drop_first=True)\n",
    "df_encoded = df_encoded.drop([\"track_id\", \"album_name\", \"artists\", \"track_name\"], axis='columns')\n",
    "df = df_encoded\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iniciação da construção do modelo e seleção de features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "A seleção das melhores features foi feita utilizando o algoritmo de **Random Forest**, que, além de ser um modelo para classificação, também oferece uma métrica interna de **importância das variáveis**. Essa métrica nos permite identificar quais são as variáveis mais relevantes para a previsão da popularidade das músicas.\n",
    "\n",
    "### Processo de Seleção\n",
    "\n",
    "1. **Treinamento do Modelo Inicial**:\n",
    "   Inicialmente, o modelo **Random Forest** foi treinado com todas as features disponíveis no dataset. Durante esse processo, o modelo calcula o impacto de cada feature na qualidade das previsões, gerando uma pontuação de importância para cada uma delas.\n",
    "\n",
    "2. **Cálculo da Importância das Features**:\n",
    "   Após o treinamento do modelo, a importância das features foi extraída. Essa importância é baseada no quanto cada feature contribui para a divisão dos nós nas árvores de decisão que compõem a Random Forest.\n",
    "\n",
    "3. **Seleção das 10 Features Mais Importantes**:\n",
    "   Com base nas pontuações de importância, as 10 features com maior impacto no modelo foram selecionadas para a construção final. Essas variáveis foram consideradas mais relevantes para prever a popularidade das músicas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop('popularity_target', axis=1)  \n",
    "y = df['popularity_target'] \n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "importances = model.feature_importances_\n",
    "feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "\n",
    "# Ordena o DataFrame pela importância\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "df = feature_importances\n",
    "\n",
    "# Exibir as 10 features mais importantes\n",
    "print(\"Top 10 Features Mais Importantes:\")\n",
    "print(feature_importances.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajustes de Hiperparâmetro\n",
    "\n",
    "Foi utilizado o **GridSearchCV** pois é uma técnica eficiente para otimizar os hiperparâmetros de modelos de aprendizado de máquina. Embora o processo de busca possa demorar um pouco, ele proporciona melhorias significativas no desempenho do modelo ao conseguir:\n",
    "\n",
    "1. **Explorar Várias Combinações de Hiperparâmetros**: O GridSearch permite testar diferentes combinações de valores para os hiperparâmetros definidos, garantindo que o modelo encontre a melhor configuração possível.\n",
    "\n",
    "2. **Selecionar Hiperparâmetros Específicos**: O GridSearch permite a personalização dos hiperparâmetros que você deseja otimizar, como o número de árvores em um modelo Random Forest (`n_estimators`) ou a profundidade máxima das árvores (`max_depth`), o que pode afetar diretamente a complexidade e o desempenho do modelo.\n",
    "\n",
    "Assim, embora o GridSearch possa exigir mais tempo de computação, o investimento em tempo frequentemente resulta em um modelo mais robusto e eficiente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [ 150, 200],  # número de árvores\n",
    "    'max_depth': [None, 10, 20],  # profundidade máxima\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search.fit(X_train_top, y_train)\n",
    "\n",
    "\n",
    "print(\"Melhores hiperparâmetros:\", grid_search.best_params_)\n",
    "\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test_top)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iniciando o modelo com Hiperparâmetros ajustados e Colunas selecionadas\n",
    "\n",
    "O inncio do treinamento do modelo **Random Forest** se deu com hiperparâmetros ajustados. Ajustando os parâmetros como o número de árvores (`n_estimators`) e a profundidade máxima (`max_depth`) para melhorar o desempenho do modelo.\n",
    "\n",
    "Além disso, está sendo ultilizado apenas as colunas mais relevantes, baseadas na importância das variáveis, garantindo que o modelo se concentre nas features que realmente impactam a previsão da popularidade das músicas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = [feature for feature in feature_importances['Feature'].head(10) if feature in X_train.columns]\n",
    "\n",
    "X_train_top = X_train[top_features]\n",
    "X_test_top = X_test[top_features]\n",
    "\n",
    "best_model = RandomForestClassifier(max_depth=None, n_estimators=200, random_state=42)\n",
    "best_model.fit(X_train_top, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test_top)\n",
    "\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsões com o Conjunto de Teste\n",
    "\n",
    "O código realiza previsões sobre a popularidade das músicas usando um conjunto de dados carregado do arquivo `test.csv`. \n",
    "\n",
    "Primeiro, as colunas relevantes são selecionadas para criar um DataFrame filtrado (`test_df_filtered`). Em seguida, o modelo treinado (`best_model`) é utilizado para fazer previsões, e os resultados são armazenados em um novo DataFrame (`output_df`). Por fim, as previsões são salvas em um arquivo CSV chamado `sample_submission.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "print(\"Colunas do test.csv após transformação:\", test_df.columns)\n",
    "\n",
    "top_features = ['track_unique_id', 'acousticness', 'energy', 'danceability', \n",
    "                'valence', 'duration_ms', 'speechiness', 'loudness', \n",
    "                'liveness', 'tempo']\n",
    "\n",
    "test_df_filtered = test_df[top_features]\n",
    "\n",
    "test_df_filtered.head(15)\n",
    "\n",
    "y_pred_new = best_model.predict(test_df_filtered)\n",
    "\n",
    "output_df = pd.DataFrame({\n",
    "    'track_unique_id': test_df['track_unique_id'],\n",
    "    'popularity_target': y_pred_new\n",
    "})\n",
    "\n",
    "output_df.to_csv('sample_submission.csv', index=False)\n",
    "\n",
    "print(\"Arquivo 'sample_submission.csv' foi salvo com sucesso!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
